{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW corpus experiments\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torchtext\n",
    "\n",
    "from w2v import utils\n",
    "from w2v import analysis\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = './data'\n",
    "year = 16\n",
    "\n",
    "wiki_files = [join(datafolder, 'wikitext-103-raw', x) for x in os.listdir(join(datafolder, 'wikitext-103-raw'))]\n",
    "wiki_files = dict(zip(['test', 'train', 'val'], sorted(wiki_files)))\n",
    "\n",
    "folders = [join(datafolder, f) for f in os.listdir(datafolder) if str(year) in f]\n",
    "files = sorted([join(folderpath, f) for folderpath in folders for f in os.listdir(folderpath)\n",
    "               if '.DS_Store' not in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore_NOW_US_2016.ipynb \u001b[34mimg\u001b[m\u001b[m                       \u001b[34mw2v\u001b[m\u001b[m\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                      \u001b[34mlogs\u001b[m\u001b[m                      \u001b[34mxdata\u001b[m\u001b[m\r\n",
      "\u001b[34mdatascripts\u001b[m\u001b[m               \u001b[34mnotebooks\u001b[m\u001b[m                 \u001b[34mxscripts\u001b[m\u001b[m\r\n",
      "\u001b[34mexe\u001b[m\u001b[m                       \u001b[34mnotes\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2016\u001b[m\u001b[m             \u001b[34msherlock\u001b[m\u001b[m         \u001b[34msources\u001b[m\u001b[m          \u001b[34mwikitext-103-raw\u001b[m\u001b[m\r\n",
      "\r\n",
      "./data/2016:\r\n",
      "16-01-us.txt 16-03-us.txt 16-05-us.txt 16-07-us.txt 16-09-us.txt 16-11-us.txt\r\n",
      "16-02-us.txt 16-04-us.txt 16-06-us.txt 16-08-us.txt 16-10-us.txt 16-12-us.txt\r\n",
      "\r\n",
      "./data/sherlock:\r\n",
      "adventures_of_sherlock_holmes.txt memoirs_of_sherlock_holmes.txt\r\n",
      "\r\n",
      "./data/sources:\r\n",
      "now_sources_pt1+2_list.txt now_sources_pt2.txt\r\n",
      "now_sources_pt1.txt\r\n",
      "\r\n",
      "./data/wikitext-103-raw:\r\n",
      "wiki.test.raw  wiki.train.raw wiki.valid.raw\r\n"
     ]
    }
   ],
   "source": [
    "! ls -R ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA for January 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file ./data/2016/16-01-us.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7000001</th>\n",
       "      <td>Here are official photos of Samsung 's crazy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000003</th>\n",
       "      <td>Sashi Brown named Browns executive VP of footb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000007</th>\n",
       "      <td>A Islamic state propaganda film shows the kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000009</th>\n",
       "      <td>John Rodriguez was walking along the coast wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000011</th>\n",
       "      <td>CINCINNATI ( AP ) -- Bengals coach Marvin Lewi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article_txt\n",
       "7000001  Here are official photos of Samsung 's crazy f...\n",
       "7000003  Sashi Brown named Browns executive VP of footb...\n",
       "7000007  A Islamic state propaganda film shows the kill...\n",
       "7000009  John Rodriguez was walking along the coast wit...\n",
       "7000011  CINCINNATI ( AP ) -- Bengals coach Marvin Lewi..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = files[0]\n",
    "print('reading file', file)\n",
    "\n",
    "data = utils.read_article_txt(file)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All sources for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = pd.concat((pd.read_csv(f'./data/sources/now_sources_pt{i}.txt', sep='\\t', \n",
    "                              encoding='latin',\n",
    "                              names=['num', 'date', 'country', 'source', 'URL', 'text'])\n",
    "        for i in [1, 2]), sort=False)\n",
    "src.date = pd.to_datetime(src.date)\n",
    "#src16.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210268, 6)\n"
     ]
    }
   ],
   "source": [
    "src16 = src[(src.date >= pd.datetime(2016, 1, 1)) & (src.date < pd.datetime(2017, 1, 1))]\n",
    "print(src16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aabir/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/aabir/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>source_lc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1350740</th>\n",
       "      <td>1101</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://www.cnn.com/2010/HEALTH/01/14/haiti.mas...</td>\n",
       "      <td>Where bodies go after natural disasters</td>\n",
       "      <td>1350740</td>\n",
       "      <td>cnn_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350741</th>\n",
       "      <td>1333</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Lawrence Journal World</td>\n",
       "      <td>http://www2.ljworld.com/news/2010/jan/16/how-i...</td>\n",
       "      <td>How important is it to have a working knowledg...</td>\n",
       "      <td>1350741</td>\n",
       "      <td>lawrence_journal_world_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350742</th>\n",
       "      <td>393</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>nwitimes.com</td>\n",
       "      <td>http://www.nwitimes.com/news/local/porter/reig...</td>\n",
       "      <td>'Reign of terror' comes to an end</td>\n",
       "      <td>1350742</td>\n",
       "      <td>nwitimes.com_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350744</th>\n",
       "      <td>2255</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Cinema Blend</td>\n",
       "      <td>http://www.cinemablend.com/games/Review-Army-o...</td>\n",
       "      <td>Review: Army of Two: The 40th Day</td>\n",
       "      <td>1350744</td>\n",
       "      <td>cinema_blend_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350745</th>\n",
       "      <td>1208</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>US</td>\n",
       "      <td>CleanTechnica</td>\n",
       "      <td>http://cleantechnica.com/2010/01/16/all-of-dub...</td>\n",
       "      <td>All of Dubai Underwater With Climate Change</td>\n",
       "      <td>1350745</td>\n",
       "      <td>cleantechnica_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num       date country                  source  \\\n",
       "1350740  1101 2016-10-01      US                     CNN   \n",
       "1350741  1333 2016-10-01      US  Lawrence Journal World   \n",
       "1350742   393 2016-10-01      US            nwitimes.com   \n",
       "1350744  2255 2016-10-01      US            Cinema Blend   \n",
       "1350745  1208 2016-10-01      US           CleanTechnica   \n",
       "\n",
       "                                                       URL  \\\n",
       "1350740  http://www.cnn.com/2010/HEALTH/01/14/haiti.mas...   \n",
       "1350741  http://www2.ljworld.com/news/2010/jan/16/how-i...   \n",
       "1350742  http://www.nwitimes.com/news/local/porter/reig...   \n",
       "1350744  http://www.cinemablend.com/games/Review-Army-o...   \n",
       "1350745  http://cleantechnica.com/2010/01/16/all-of-dub...   \n",
       "\n",
       "                                                      text       id  \\\n",
       "1350740            Where bodies go after natural disasters  1350740   \n",
       "1350741  How important is it to have a working knowledg...  1350741   \n",
       "1350742                  'Reign of terror' comes to an end  1350742   \n",
       "1350744                  Review: Army of Two: The 40th Day  1350744   \n",
       "1350745        All of Dubai Underwater With Climate Change  1350745   \n",
       "\n",
       "                       source_lc  \n",
       "1350740                     cnn_  \n",
       "1350741  lawrence_journal_world_  \n",
       "1350742            nwitimes.com_  \n",
       "1350744            cinema_blend_  \n",
       "1350745           cleantechnica_  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src16['id'] = src16.index\n",
    "src16['source_lc'] = src16.source.apply(lambda x: '_'.join(x.lower().split()) + '_')\n",
    "\n",
    "src16 = src16[src16.country=='US']\n",
    "src16.index = src16.index.astype('str')\n",
    "src16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total sources: 20733\n",
      "# total publications: 6132175\n",
      "# publications with 'news' in name: 3301\n",
      "# publications with 'blog' in name: 394\n",
      "# publications with 'journal' in name: 652\n",
      "# publications with 'post' in name: 1570\n",
      "# publications with 'magazine' in name: 760\n",
      "# publications with 'radio' in name: 109\n",
      "# publications with 'sport' in name: 245\n"
     ]
    }
   ],
   "source": [
    "counts = {k: src16['source_lc'].str.contains(k).sum() for k in ['news', 'blog', 'journal',\n",
    "                                                                'post', 'magazine', 'radio', 'sport']}\n",
    "\n",
    "print(f\"# total sources: {len(src.source.unique())}\")\n",
    "print(f\"# total publications: {len(src)}\")\n",
    "for k, v in counts.items():\n",
    "    print(f\"# publications with '{k}' in name: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideology map source: allsides.com\n",
    "\n",
    "ideology_map = {'left':['huffington', 'msnbc', 'cnn', 'slate magazine_', 'daily beast', 'new yorker_'],\n",
    "                'lean_left': ['the guardian_', 'politico_', 'propublica', 'bloomberg_'],\n",
    "                'centre': ['reuters', 'wall street journal_', 'npr_', 'usa today_'],\n",
    "                'lean_right': ['american conservative', 'epoch times', 'examiner.com'],\n",
    "                'right': ['fox news_', 'national review_', 'breitbart', 'federalist_', 'theblaze',\n",
    "                          'american spectator', 'daily caller', 'newsmax', ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n",
      "\t huffington: 1010 | Huffington Post , Huffington Post (satire), Huffington Post, Huffington Post UK\n",
      "\t msnbc: 16 | msnbc.com, MSNBC\n",
      "\t cnn: 499 | CNN, CNNMoney.com, CNN International, CNNMoney, CNN , CNN Political Ticker , CNN - Canada, CNNMoney \n",
      "\t slate magazine_: 0 | \n",
      "\t daily beast: 0 | \n",
      "\t new yorker_: 0 | \n",
      "total = 1525\n",
      "\n",
      "lean_left\n",
      "\t the guardian_: 0 | \n",
      "\t politico_: 76 | Politico, Politico , POLITICO Magazine, Politico (blog)\n",
      "\t propublica: 17 | ProPublica\n",
      "\t bloomberg_: 146 | Bloomberg, Bloomberg BNA, Bloomberg View\n",
      "total = 239\n",
      "\n",
      "centre\n",
      "\t reuters: 203 | Reuters, Reuters Blogs , Reuters India , Reuters Africa , Reuters AlertNet, Thomson Reuters Foundation, Reuters Africa\n",
      "\t wall street journal_: 0 | \n",
      "\t npr_: 526 | NPR, NPR \n",
      "\t usa today_: 0 | \n",
      "total = 729\n",
      "\n",
      "lean_right\n",
      "\t american conservative: 0 | \n",
      "\t epoch times: 0 | \n",
      "\t examiner.com: 10 | Examiner.com\n",
      "total = 10\n",
      "\n",
      "right\n",
      "\t fox news_: 0 | \n",
      "\t national review_: 0 | \n",
      "\t breitbart: 15 | Breitbart News, Breitbart News \n",
      "\t federalist_: 7 | The Federalist\n",
      "\t theblaze: 88 | TheBlaze.com, TheBlaze.com \n",
      "\t american spectator: 0 | \n",
      "\t daily caller: 0 | \n",
      "\t newsmax: 26 | NewsMax.com, Newsmax.com, Newsmax\n",
      "total = 136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.summarize_sources(ideology_map, src16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data for Fox News, Huffington Post, CNN, Reuters, and Breitbart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = utils.get_data_per_source(['fox_news_', 'huffington', 'cnn_', 'reuters', 'breitbart'], src16, limit=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_txt</th>\n",
       "      <th>num</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>source_lc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7394830</th>\n",
       "      <td>EFE News Briefs for Tuesday , Feb. 16 ( End of...</td>\n",
       "      <td>632</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News Latino</td>\n",
       "      <td>http://latino.foxnews.com/latino/news/2016/02/...</td>\n",
       "      <td>EFE News Briefs for Tuesday, Feb. 16 (End of t...</td>\n",
       "      <td>7394830</td>\n",
       "      <td>fox_news_latino_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395486</th>\n",
       "      <td>Eagles of Death Metal frontman slams French gu...</td>\n",
       "      <td>450</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://www.foxnews.com/entertainment/2016/02/1...</td>\n",
       "      <td>Eagles of Death Metal frontman slams French gu...</td>\n",
       "      <td>7395486</td>\n",
       "      <td>fox_news_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14894298</th>\n",
       "      <td>Iraqi PM announces start of military offensive...</td>\n",
       "      <td>729</td>\n",
       "      <td>2016-10-16</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://www.foxnews.com/world/2016/10/16/iraqi-...</td>\n",
       "      <td>Iraqi PM announces start of military offensive...</td>\n",
       "      <td>14894298</td>\n",
       "      <td>fox_news_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297323</th>\n",
       "      <td>Woman accusing Bill Cosby of sexual assualt al...</td>\n",
       "      <td>376</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://www.foxnews.com/entertainment/2016/04/1...</td>\n",
       "      <td>Woman accusing Bill Cosby of sexual assualt al...</td>\n",
       "      <td>8297323</td>\n",
       "      <td>fox_news_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299800</th>\n",
       "      <td>Anger at the IRS has rarely been higher . Poli...</td>\n",
       "      <td>1099</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://www.foxnews.com/politics/2016/04/16/fir...</td>\n",
       "      <td>Fiery GOP rhetoric about impeaching IRS chief ...</td>\n",
       "      <td>8299800</td>\n",
       "      <td>fox_news_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article_txt   num       date  \\\n",
       "7394830   EFE News Briefs for Tuesday , Feb. 16 ( End of...   632 2016-02-16   \n",
       "7395486   Eagles of Death Metal frontman slams French gu...   450 2016-02-16   \n",
       "14894298  Iraqi PM announces start of military offensive...   729 2016-10-16   \n",
       "8297323   Woman accusing Bill Cosby of sexual assualt al...   376 2016-04-16   \n",
       "8299800   Anger at the IRS has rarely been higher . Poli...  1099 2016-04-16   \n",
       "\n",
       "         country           source  \\\n",
       "7394830       US  Fox News Latino   \n",
       "7395486       US         Fox News   \n",
       "14894298      US         Fox News   \n",
       "8297323       US         Fox News   \n",
       "8299800       US         Fox News   \n",
       "\n",
       "                                                        URL  \\\n",
       "7394830   http://latino.foxnews.com/latino/news/2016/02/...   \n",
       "7395486   http://www.foxnews.com/entertainment/2016/02/1...   \n",
       "14894298  http://www.foxnews.com/world/2016/10/16/iraqi-...   \n",
       "8297323   http://www.foxnews.com/entertainment/2016/04/1...   \n",
       "8299800   http://www.foxnews.com/politics/2016/04/16/fir...   \n",
       "\n",
       "                                                       text        id  \\\n",
       "7394830   EFE News Briefs for Tuesday, Feb. 16 (End of t...   7394830   \n",
       "7395486   Eagles of Death Metal frontman slams French gu...   7395486   \n",
       "14894298  Iraqi PM announces start of military offensive...  14894298   \n",
       "8297323   Woman accusing Bill Cosby of sexual assualt al...   8297323   \n",
       "8299800   Fiery GOP rhetoric about impeaching IRS chief ...   8299800   \n",
       "\n",
       "                 source_lc  \n",
       "7394830   fox_news_latino_  \n",
       "7395486          fox_news_  \n",
       "14894298         fox_news_  \n",
       "8297323          fox_news_  \n",
       "8299800          fox_news_  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['fox_news_'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikidata for base model\n",
    "\n",
    "Dataset link/source: https://huggingface.co/datasets/wikitext\n",
    "\n",
    "The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \r\n",
      " = Valkyria Chronicles III = \r\n",
      " \r\n",
      " Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \r\n"
     ]
    }
   ],
   "source": [
    "! head -n 4 ./data/wikitext-103-raw/wiki.train.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip punctuation\n",
    "no_punc = lambda x: x.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>6438871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2743109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2505747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>2176394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1994956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     wordcount\n",
       "the    6438871\n",
       "of     2743109\n",
       "and    2505747\n",
       "in     2176394\n",
       "to     1994956"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcounts = utils.wordcounter(filename=wiki_files['train'], txtprocess_func=no_punc)\n",
    "\n",
    "# top 5 most common words\n",
    "wordcounts.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxcounts = utils.wordcounter(txt=dfs['fox_news_'].article_txt.tolist(), txtprocess_func=no_punc)\n",
    "cnncounts = utils.wordcounter(txt=dfs['cnn_'].article_txt.tolist(), txtprocess_func=no_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     wordcount\n",
       "the        885\n",
       "to         423\n",
       "of         360\n",
       "in         312\n",
       "a          296"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foxcounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     wordcount\n",
       "the       2116\n",
       "of        1091\n",
       "a          855\n",
       "in         821\n",
       "to         818"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnncounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiData: \n",
      "\t231700/537508 words occur only 1 time\n",
      "Fox News articles: \n",
      "\t2115/3587 words occur only 1 time\n",
      "CNN articles: \n",
      "\t3173/6117 words occur only 1 time\n"
     ]
    }
   ],
   "source": [
    "print(f\"WikiData: \\n\\t{wordcounts[wordcounts.wordcount==1].shape[0]}/{wordcounts.shape[0]} words occur only 1 time\")\n",
    "print(f\"Fox News articles: \\n\\t{foxcounts[foxcounts.wordcount==1].shape[0]}/{foxcounts.shape[0]} words occur only 1 time\")\n",
    "\n",
    "print(f\"CNN articles: \\n\\t{cnncounts[cnncounts.wordcount==1].shape[0]}/{cnncounts.shape[0]} words occur only 1 time\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fox News articles: \n",
      "\t2139/3626 words occur only 1 time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3626.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.715895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>885.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wordcount\n",
       "count  3626.000000\n",
       "mean      4.500552\n",
       "std      28.715895\n",
       "min       1.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       3.000000\n",
       "max     885.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wordcounts.describe()\n",
    "#foxcounts.describe()\n",
    "#cnncounts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wiki-103': 537508, 'fox_news_': 3587, 'cnn_': 6117}\n"
     ]
    }
   ],
   "source": [
    "vocab_sizes = dict(zip(['wiki-103', 'fox_news_', 'cnn_'], [s[0] for s in (wordcounts.shape, foxcounts.shape, cnncounts.shape)]))\n",
    "print(vocab_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fox common words = 3449/3587\n",
      "CNN common words = 5833/6117\n",
      "CNN Fox common words = 1986\n"
     ]
    }
   ],
   "source": [
    "fox_common_vocab = foxcounts.index.intersection(wordcounts.index)\n",
    "cnn_common_vocab = cnncounts.index.intersection(wordcounts.index)\n",
    "\n",
    "print(f\"Fox common words = {fox_common_vocab.shape[0]}/{foxcounts.shape[0]}\")\n",
    "print(f\"CNN common words = {cnn_common_vocab.shape[0]}/{cnncounts.shape[0]}\")\n",
    "\n",
    "full_vocab = foxcounts.index.intersection(cnncounts.index)\n",
    "\n",
    "print(f'CNN Fox common words = {len(full_vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wvs(dfs):\n",
    "    # dfs: dict\n",
    "    wvs = {}\n",
    "    for term in df.keys():\n",
    "        wvs[term] = Word2Vec([l.split(' ') for l in dfs[term].article_txt.tolist()], size=64).wv\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxw2v = Word2Vec([l.split(' ') for l in dfs['fox news_'].article_txt.tolist()], size=128)\n",
    "cnnw2v = Word2Vec([l.split(' ') for l in dfs['cnn_'].article_txt.tolist()], size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['war', 'religion', 'immigrant', 'tax', 'economic', 'welfare', 'racism', 'history', 'America',\n",
    "        'violence', 'health', 'crime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foxw2v.wv.most_similar(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnw2v.wv.most_similar(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
